# Data Modeling using Postgres Database

## **Overview**
This project uses data modeling skills to build an ETL pipeline that extracts their data from S3, stages them in Redshift, and transforms data into a set of dimensional tables for an analytics team to continue finding insights in what songs their users are listening to.

## **Song Dataset**
The first dataset is a subset of real data from the [Million Song Dataset](http://millionsongdataset.com/). Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.

Sample Song Data:
```
{"num_songs": 1, "artist_id": "ARJIE2Y1187B994AB7", "artist_latitude": null, "artist_longitude": null, "artist_location": "", "artist_name": "Line Renaud", "song_id": "SOUPIRU12A6D4FA1E1", "title": "Der Kleine Dompfaff", "duration": 152.92036, "year": 0}
```
## **Log Dataset**
The second dataset consists of log files in JSON format generated by this [event simulator](https://github.com/Interana/eventsim) based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.

Sample Log Data:
```
{"artist": Stephen Lynch, "auth": "Logged In", "firstName": "Jayden", "gender": "M", "itemInSession": 0, "lastName": "Bell", "length": 182.85669, "level": "free", "location": "Dallas-Fort Worth-Arlington, TX", "method": "PUT","page": "NextSong", "registration": 1.540992e+12, "sessionId": 829, "song": "Jim Henson's Dead", "status": 200, "ts": 1541105830796, "userAgent": "\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"", "userId": "91"}
```

## Schema

### Fact Table
**songplays** - records in log data associated with song plays i.e. records with page `NextSong`

```
songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent
```

### Dimension Tables
**users**  - users in the app
```
user_id, first_name, last_name, gender, level
```
**songs**  - songs in music database
```
song_id, title, artist_id, year, duration
```
**artists**  - artists in music database
```
artist_id, name, location, latitude, longitude
```
**time**  - timestamps of records in  **songplays**  broken down into specific units
```
start_time, hour, day, week, month, year, weekday
```

## Project Files
```create_tables.py``` -> module for create database and initializing tables.

```sql_queries.py``` -> module that contains all required sql queries.

```etl.ipynb``` -> a notebook for running tests and exploring project code.

```etl.py``` -> module to run all extract transform and load processes for song and long datasets

```test.ipynb``` -> a test notebook to connect to database and validate extract and load processes.


## Environment 
Python 3.6 or above

AWS Redshift

psycopg2 - PostgreSQL database adapter for Python

## Running the Program
Run create_tables and etl modules
```
python Redshift_IaC.py
python create_tables.py
python etl.py
```

